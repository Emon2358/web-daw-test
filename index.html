<!DOCTYPE html>
<html lang="ja" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web ZMUSIC (X68k Sampler Simulator)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* スクロールバーのスタイル */
        ::-webkit-scrollbar { width: 8px; height: 8px; }
        ::-webkit-scrollbar-track { background: #2d3748; }
        ::-webkit-scrollbar-thumb { background: #718096; border-radius: 4px; }
        ::-webkit-scrollbar-thumb:hover { background: #a0aec0; }
        
        /* 選択範囲のスタイル */
        ::selection { background-color: #4a90e2; color: white; }
        
        /* スマホ用タブUI */
        .tab-content { display: none; }
        .tab-content.active { display: block; }

        @media (max-width: 1023px) {
            .grid-cols-4 { display: none; } /* PCレイアウトを隠す */
            .tabs-container { display: block; } /* スマホレイアウトを表示 */
        }
        @media (min-width: 1024px) {
            .tabs-container { display: none; } /* スマホレイアウトを隠す */
        }
    </style>
</head>
<body class="font-mono bg-gray-900 text-gray-200 h-full flex flex-col p-2 sm:p-4 overflow-hidden">

    <div classs="w-full max-w-7xl mx-auto flex flex-col h-full">

        <!-- 1. ヘッダーとメインコントロール -->
        <header class="mb-3">
            <h1 class="text-xl sm:text-2xl font-bold text-white mb-2">Web ZMUSIC <span class="text-sm font-normal text-gray-400">(X68k Sampler Sim)</span></h1>
            
            <div class="flex flex-wrap items-center gap-2 sm:gap-4 p-3 bg-gray-800 rounded-lg border border-gray-700">
                <!-- ディレクトリパス -->
                <div class="flex-grow min-w-[200px]">
                    <label for="currentDir" class="text-xs text-gray-400">Current Directory:</label>
                    <input type="text" id="currentDir" value="A:\CD_WORKS\gabba\" class="w-full bg-gray-900 text-green-400 px-2 py-1 rounded border border-gray-600 text-sm">
                </div>
                <!-- メインコントロール -->
                <div class="flex items-center gap-2">
                    <button id="playButton" class="px-4 py-2 bg-green-600 hover:bg-green-700 rounded-lg font-bold text-white transition-colors">
                        PLAY (BAT)
                    </button>
                    <button id="stopButton" class="px-4 py-2 bg-red-600 hover:bg-red-700 rounded-lg font-bold text-white transition-colors">
                        STOP (BAT)
                    </button>
                </div>
                <!-- プロジェクト保存/読み込み -->
                <div class="flex items-center gap-2">
                    <button id="saveProjectButton" class="px-3 py-2 bg-blue-600 hover:bg-blue-700 rounded-lg text-white text-sm">
                        Save Project
                    </button>
                    <label class="px-3 py-2 bg-purple-600 hover:bg-purple-700 rounded-lg text-white text-sm cursor-pointer">
                        Load Project
                        <input type="file" id="loadProjectInput" accept=".json" class="hidden">
                    </label>
                </div>
            </div>
        </header>

        <!-- 2. メインレイアウト (ファイル管理 + エディタ) -->
        <main class="flex-1 grid grid-cols-1 lg:grid-cols-3 gap-3 overflow-hidden">

            <!-- 2.1. 左カラム: ファイル管理 -->
            <aside class="bg-gray-800 p-4 rounded-lg border border-gray-700 overflow-y-auto flex flex-col gap-4">
                
                <!-- 1. ソース音声のロード -->
                <div>
                    <h3 class="text-lg font-medium text-gray-300 mb-2">1. ソース音声のロード</h3>
                    <p class="text-sm text-gray-400 mb-2">WAV, MP3, M4A 等のファイルをロードし、サンプラー（2）で切り出します。</p>
                    <label class="mb-2 block w-full text-sm text-gray-400
                        file:mr-4 file:py-2 file:px-4
                        file:rounded-lg file:border-0
                        file:text-sm file:font-semibold
                        file:bg-indigo-600 file:text-white
                        hover:file:bg-indigo-700 cursor-pointer">
                        + ソースをロード
                        <input type="file" id="sourceAudioUpload" multiple accept="audio/*" class="hidden">
                    </label>
                    <div id="sourceAudioList" class="bg-gray-900 p-3 rounded-md h-32 overflow-y-auto border border-gray-700">
                        <p class="text-gray-500">音声ファイルをロードしてください...</p>
                    </div>
                </div>

                <!-- 2. 波形サンプラー -->
                <div>
                    <h3 class="text-lg font-medium text-gray-300 mb-2">2. 波形サンプラー</h3>
                    <div class="relative bg-black rounded-md border border-gray-700 h-40">
                        <canvas id="waveformCanvas" class="w-full h-full cursor-crosshair"></canvas>
                        <!-- ズームボタン -->
                        <div class="absolute top-2 right-2 flex gap-1">
                            <button id="zoomOutButton" class="px-2 py-0.5 bg-gray-700 hover:bg-gray-600 text-white rounded text-sm">-</button>
                            <button id="zoomInButton" class="px-2 py-0.5 bg-gray-700 hover:bg-gray-600 text-white rounded text-sm">+</button>
                            <button id="zoomAllButton" class="px-2 py-0.5 bg-gray-700 hover:bg-gray-600 text-white rounded text-sm">All</button>
                        </div>
                    </div>
                    <p id="selectionInfo" class="text-xs text-gray-400 mt-1">
                        Drag: Select / Wheel: Pan / Ctrl+Wheel: Zoom
                    </p>
                    <div class="flex gap-2 mt-2">
                        <input type="text" id="sampleFileName" placeholder="sample.m44" class="flex-grow bg-gray-900 text-white px-2 py-1 rounded border border-gray-600 text-sm">
                        <button id="cutButton" class="px-4 py-1 bg-green-600 hover:bg-green-700 rounded-lg text-white text-sm">
                            切り出し保存
                        </button>
                    </div>
                </div>

                <!-- 3. マイク録音 -->
                <div>
                    <h3 class="text-lg font-medium text-gray-300 mb-2">3. マイク録音 (サンプリング)</h3>
                    <div class="flex gap-2">
                        <input type="text" id="recordFileName" placeholder="voice1.m44" class="flex-grow bg-gray-900 text-white px-2 py-1 rounded border border-gray-600 text-sm">
                        <button id="recordButton" class="px-4 py-1 bg-red-600 hover:bg-red-700 rounded-lg text-white text-sm">
                            ● REC
                        </button>
                    </div>
                </div>

                <!-- 4. サンプルバンク -->
                <div>
                    <h3 class="text-lg font-medium text-gray-300 mb-2">4. サンプルバンク (.m44 / .wav / .mp3)</h3>
                    <p class="text-sm text-gray-400 mb-2">.cfgファイルから参照される音声サンプルです。</p>
                    
                    <label class="mb-4 block w-full text-sm text-gray-400
                        file:mr-4 file:py-2 file:px-4
                        file:rounded-lg file:border-0
                        file:text-sm file:font-semibold
                        file:bg-blue-600 file:text-white
                        hover:file:bg-blue-700 cursor-pointer">
                        + バンクにサンプルをロード
                        <input type="file" id="bankAudioUpload" multiple accept="audio/*" class="hidden">
                    </label>
                    
                    <div id="fileList" class="bg-gray-900 p-3 rounded-md h-48 overflow-y-auto border border-gray-700">
                        <p class="text-gray-500">音声ファイルをロードまたは録音してください...</p>
                    </div>
                </div>

            </aside>

            <!-- 2.2. 右カラム: エディタ群 -->
            <div class="lg:col-span-2 flex flex-col overflow-hidden">

                <!-- スマホ用タブ (lg未満で表示) -->
                <div class="tabs-container lg:hidden mb-2">
                    <div class="flex border-b border-gray-700">
                        <button data-tab="tab-bat" class="tab-button flex-1 py-2 px-1 text-sm bg-gray-700 text-white rounded-t-md">gabba.BAT</button>
                        <button data-tab="tab-stop" class="tab-button flex-1 py-2 px-1 text-sm bg-gray-800 text-gray-400">STOP.BAT</button>
                        <button data-tab="tab-cfg" class="tab-button flex-1 py-2 px-1 text-sm bg-gray-800 text-gray-400">gabba.cfg</button>
                        <button data-tab="tab-zms" class="tab-button flex-1 py-2 px-1 text-sm bg-gray-800 text-gray-400">gabba.zms</button>
                    </div>
                </div>

                <!-- エディタ本体 (PC用グリッド + スマホ用タブコンテナ) -->
                <div class="grid-cols-4 gap-3 h-full hidden lg:grid"> <!-- PC用 -->
                    <div id="pc-tab-bat" class="h-full flex flex-col"></div>
                    <div id="pc-tab-stop" class="h-full flex flex-col"></div>
                    <div id="pc-tab-cfg" class="h-full flex flex-col"></div>
                    <div id="pc-tab-zms" class="h-full flex flex-col"></div>
                </div>
                
                <div class="tabs-content-container flex-1 overflow-hidden"> <!-- スマホ用 -->
                    <div id="tab-bat" class="tab-content active h-full flex flex-col"></div>
                    <div id="tab-stop" class="tab-content h-full flex flex-col"></div>
                    <div id="tab-cfg" class="tab-content h-full flex flex-col"></div>
                    <div id="tab-zms" class="tab-content h-full flex flex-col"></div>
                </div>

            </div>
        </main>

        <!-- 3. コンソールログ -->
        <footer class="mt-3 h-32 lg:h-24">
            <div id="consoleLog" class="bg-black text-green-400 font-mono text-xs p-3 rounded-lg border border-gray-700 h-full overflow-y-auto">
                <p>&gt; Web ZMUSIC v1.5 Initialized. (Waiting for user interaction to start AudioContext...)</p>
            </div>
        </footer>
    </div>


    <script>
        // --- グローバル変数 ---
        let audioContext;
        let masterGain;
        const audioBuffers = new Map(); // サンプルバンク (key: filename, value: AudioBuffer)
        const sourceAudioBuffers = new Map(); // ソース音声 (key: filename, value: AudioBuffer)
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        let mmlPlayer = null; // MML再生エンジン
        let nextNoteTime = 0.0;
        let tempo = 120.0;
        let activeSources = []; // 再生中の音源

        // サンプラー用
        let currentSamplerBuffer = null; // 波形表示中のBuffer
        let currentSamplerFileName = null; // 波形表示中のファイル名
        let selectionStart = 0; // 選択開始サンプル
        let selectionEnd = 0; // 選択終了サンプル
        let zoomLevel = 1;
        let viewOffset = 0; // サンプル単位

        // エディタDOM
        const consoleLog = document.getElementById('consoleLog');
        const playButton = document.getElementById('playButton');
        const stopButton = document.getElementById('stopButton');
        const fileList = document.getElementById('fileList');
        const recordButton = document.getElementById('recordButton');
        const recordFileNameInput = document.getElementById('recordFileName');
        
        // ソース
        const sourceAudioUpload = document.getElementById('sourceAudioUpload');
        const sourceAudioList = document.getElementById('sourceAudioList');

        // バンク
        const bankAudioUpload = document.getElementById('bankAudioUpload');

        // サンプラー
        const waveformCanvas = document.getElementById('waveformCanvas');
        const canvasCtx = waveformCanvas.getContext('2d');
        const cutButton = document.getElementById('cutButton');
        const sampleFileNameInput = document.getElementById('sampleFileName');
        const selectionInfo = document.getElementById('selectionInfo');
        const zoomInButton = document.getElementById('zoomInButton');
        const zoomOutButton = document.getElementById('zoomOutButton');
        const zoomAllButton = document.getElementById('zoomAllButton');

        // プロジェクト保存/読み込み
        const saveProjectButton = document.getElementById('saveProjectButton');
        const loadProjectInput = document.getElementById('loadProjectInput');

        // --- 1. 音声処理コア (最重要) ---

        /**
         * AudioContextを初期化し、ブラウザの自動再生ポリシーにより
         * 'suspended' 状態の場合は 'running' に復帰させる。
         * 音声関連の操作の前に必ず呼び出す。
         */
        async function initAudio() {
            if (audioContext && audioContext.state === 'running') {
                return; // 既に実行中
            }
            
            if (!audioContext) {
                try {
                    // Safari/iOS対策も含む
                    window.AudioContext = window.AudioContext || window.webkitAudioContext;
                    audioContext = new AudioContext();
                    
                    masterGain = audioContext.createGain();
                    masterGain.connect(audioContext.destination);
                    
                    log('AudioContext initialized.');

                } catch (e) {
                    log('Error initializing AudioContext: ' + e.message, true);
                    alert('Web Audio API is not supported in this browser.');
                    return;
                }
            }

            // 'suspended' 状態（ユーザー操作待ち）の場合、再開を試みる
            if (audioContext.state === 'suspended') {
                try {
                    await audioContext.resume();
                    log('AudioContext resumed successfully.');
                } catch (e) {
                    log('Failed to resume AudioContext (will retry on next user interaction): ' + e.message, true);
                }
            }
        }


        // --- 2. ログ出力 ---
        function log(message, isError = false) {
            if (isError) {
                console.error(message);
                consoleLog.innerHTML += `<p class="text-red-500">&gt; ${message}</p>`;
            } else {
                console.log(message);
                consoleLog.innerHTML += `<p>&gt; ${message}</p>`;
            }
            consoleLog.scrollTop = consoleLog.scrollHeight;
        }

        // --- 3. エディタとUIの管理 ---

        // シンプルなインメモリエディタクラス
        class TextEditor {
            constructor(containerId, fileName, content) {
                this.container = document.getElementById(containerId);
                this.fileName = fileName;
                
                // ファイル名入力
                this.nameInput = document.createElement('input');
                this.nameInput.type = 'text';
                this.nameInput.value = fileName;
                this.nameInput.className = "w-full bg-gray-900 text-yellow-400 px-2 py-1 rounded-t border-b border-gray-700 text-sm focus:outline-none";
                this.container.appendChild(this.nameInput);

                // テキストエリア
                this.textarea = document.createElement('textarea');
                this.textarea.value = content;
                this.textarea.className = "w-full flex-1 bg-gray-800 p-2 rounded-b text-sm focus:outline-none resize-none";
                this.textarea.setAttribute('spellcheck', 'false');
                this.container.appendChild(this.textarea);

                // ファイル名変更をインスタンスに反映
                this.nameInput.addEventListener('change', (e) => {
                    this.fileName = e.target.value;
                });
            }

            getContent() {
                return this.textarea.value;
            }
            
            setContent(content) {
                this.textarea.value = content;
            }

            getFileName() {
                // nameInputから最新の値を取得
                return this.nameInput.value;
            }
            
            setFileName(name) {
                this.nameInput.value = name;
                this.fileName = name;
            }
        }

        // エディタの初期化
        const editors = {
            bat: new TextEditor('pc-tab-bat', 'gabba.BAT', 
`pcm8pp -c8 -f7
zmusic -a -p3000
zmusic -d
zp gabba.zms`),
            stop: new TextEditor('pc-tab-stop', 'STOP.BAT', 
`zp -s
zmusic -r
pcm8pp -r`),
            cfg: new TextEditor('pc-tab-cfg', 'gabba.cfg', 
`/* ADPCM BANK1
.adpcm_bank=1
.o2c = kick.m44
.o2d = snar.m44
.o2f = hhc.m44
.o2f+= hho.m44
.o2a = clap.m44
.o2b = crash.m44
.o3c = melo1.m44
.o3d = melo2.m44
.o4c = voice1.m44
.o4d = voice2.m44
`),
            zms: new TextEditor('pc-tab-zms', 'gabba.zms', 
`/* ZMS (MML)
t140
A o2 l8 cdefgab>c
A r4 c d f f+
A r4 a g f <b
B o4 l16 c..d e..f g..a b..>c
`)
        };

        // スマホ用タブのクローン
        document.getElementById('tab-bat').appendChild(editors.bat.container.cloneNode(true));
        document.getElementById('tab-stop').appendChild(editors.stop.container.cloneNode(true));
        document.getElementById('tab-cfg').appendChild(editors.cfg.container.cloneNode(true));
        document.getElementById('tab-zms').appendChild(editors.zms.container.cloneNode(true));

        // スマホ用タブ切り替えロジック
        document.querySelectorAll('.tab-button').forEach(button => {
            button.addEventListener('click', () => {
                const tabId = button.getAttribute('data-tab');

                // 全タブを非アクティブ化
                document.querySelectorAll('.tab-button').forEach(btn => {
                    btn.classList.remove('bg-gray-700', 'text-white');
                    btn.classList.add('bg-gray-800', 'text-gray-400');
                });
                document.querySelectorAll('.tab-content').forEach(content => {
                    content.classList.remove('active');
                });

                // クリックされたタブをアクティブ化
                button.classList.add('bg-gray-700', 'text-white');
                button.classList.remove('bg-gray-800', 'text-gray-400');
                document.getElementById(tabId).classList.add('active');
            });
        });

        // --- 4. ファイル管理 (ロード/録音/保存) ---

        // 4.1. ソース音声のロード (セクション1)
        sourceAudioUpload.addEventListener('change', async (event) => {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲
            
            const files = event.target.files;
            if (files.length === 0) return;

            if (sourceAudioList.querySelector('p')) {
                sourceAudioList.innerHTML = ''; // 「...」メッセージをクリア
            }

            Array.from(files).forEach(file => {
                if (sourceAudioBuffers.has(file.name)) {
                    log(`Warning: Source audio ${file.name} already exists. Overwriting.`, true);
                    // UIから削除
                    Array.from(sourceAudioList.children).forEach(child => {
                        if (child.textContent === file.name) child.remove();
                    });
                }
                addSourceAudioFile(file.name, file);
            });
            sourceAudioUpload.value = ''; // 同じファイルを再度選択できるようにする
        });

        async function addSourceAudioFile(fileName, file) {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲
            
            log(`Loading source audio: ${fileName}...`);
            const fileReader = new FileReader();
            
            fileReader.onload = async (e) => {
                try {
                    // ▼▼▼ 修正: AudioContextを起動 (コールバック内でも念のため) ▼▼▼
                    await initAudio(); 
                    // ▲▲▲ 修正 ▲▲▲
                    
                    const buffer = await audioContext.decodeAudioData(e.target.result);
                    sourceAudioBuffers.set(fileName, buffer);
                    
                    // UIに追加
                    const fileItem = document.createElement('div');
                    fileItem.className = 'p-2 bg-gray-800 rounded mb-1 text-sm cursor-pointer hover:bg-indigo-700';
                    fileItem.textContent = fileName;
                    fileItem.onclick = () => loadWaveform(fileName);
                    sourceAudioList.appendChild(fileItem);
                    log(`Loaded source audio: ${fileName}`);
                    
                } catch (err) {
                    log(`Error decoding source audio ${fileName}: ${err.message}`, true);
                }
            };
            fileReader.onerror = () => {
                log(`Error reading source file ${fileName}`, true);
            };
            fileReader.readAsArrayBuffer(file);
        }

        // 4.2. バンクへの直接ロード (セクション4)
        bankAudioUpload.addEventListener('change', async (event) => {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲
            
            const files = event.target.files;
            if (files.length === 0) return;

            if (fileList.querySelector('p')) {
                fileList.innerHTML = ''; // 「...」メッセージをクリア
            }
            
            Array.from(files).forEach(file => {
                if (audioBuffers.has(file.name)) {
                    log(`Warning: File ${file.name} already in bank. Overwriting.`, true);
                    Array.from(fileList.children).forEach(child => {
                        if (child.textContent.startsWith(file.name)) child.remove();
                    });
                }
                addAudioFile(file.name, file);
            });
            bankAudioUpload.value = '';
        });

        // 4.3. 録音 (セクション3)
        recordButton.addEventListener('click', async () => {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲

            if (isRecording) {
                // 録音停止
                mediaRecorder.stop();
                recordButton.textContent = '● REC';
                recordButton.classList.remove('animate-pulse', 'bg-yellow-500', 'hover:bg-yellow-600');
                recordButton.classList.add('bg-red-600', 'hover:bg-red-700');
                isRecording = false;
                log('Recording stopped.');
            } else {
                // 録音開始
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.start();
                    
                    audioChunks = []; // チャンクをリセット
                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        const fileName = recordFileNameInput.value || `rec_${Date.now()}.wav`; // .wavに
                        
                        if (audioBuffers.has(fileName)) {
                            log(`Warning: File ${fileName} already in bank. Overwriting.`, true);
                        }
                        
                        addAudioFile(fileName, audioBlob);
                        
                        // ストリームを停止
                        stream.getTracks().forEach(track => track.stop());
                    };

                    recordButton.textContent = '■ STOP';
                    recordButton.classList.add('animate-pulse', 'bg-yellow-500', 'hover:bg-yellow-600');
                    recordButton.classList.remove('bg-red-600', 'hover:bg-red-700');
                    isRecording = true;
                    log('Recording started... Press STOP to finish.');

                } catch (err) {
                    log('Error starting recording: ' + err.message, true);
                    alert('Could not access microphone. Please grant permission.');
                }
            }
        });

        // 4.4. サンプルバンクへのオーディオバッファ追加 (共通関数)
        async function addAudioFile(fileName, fileObjectOrBlob) {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲
            
            log(`Loading to bank: ${fileName}...`);
            const fileReader = new FileReader();
            
            fileReader.onload = async (e) => {
                try {
                    // ▼▼▼ 修正: AudioContextを起動 (コールバック内でも念のため) ▼▼▼
                    await initAudio(); 
                    // ▲▲▲ 修正 ▲▲▲
                    
                    const buffer = await audioContext.decodeAudioData(e.target.result);
                    audioBuffers.set(fileName, buffer);
                    
                    // UIの「...」をクリア
                    if (fileList.querySelector('p')) {
                        fileList.innerHTML = '';
                    }

                    // UIにファイル追加
                    const fileItem = document.createElement('div');
                    fileItem.className = 'p-2 bg-gray-700 rounded mb-1 text-sm flex justify-between items-center';
                    
                    const nameSpan = document.createElement('span');
                    nameSpan.textContent = `${fileName} (${(buffer.duration * 1000).toFixed(0)} ms)`;
                    fileItem.appendChild(nameSpan);

                    const deleteBtn = document.createElement('button');
                    deleteBtn.textContent = 'x';
                    deleteBtn.className = 'px-2 py-0 text-red-400 hover:text-red-200';
                    deleteBtn.onclick = (e) => {
                        e.stopPropagation();
                        audioBuffers.delete(fileName);
                        fileItem.remove();
                        log(`Removed ${fileName} from bank.`);
                    };
                    fileItem.appendChild(deleteBtn);

                    fileList.appendChild(fileItem);
                    log(`Loaded ${fileName} into sample bank.`);

                } catch (err) {
                    log(`Error decoding audio ${fileName}: ${err.message}`, true);
                }
            };
            fileReader.onerror = () => {
                log(`Error reading file ${fileName}`, true);
            };
            fileReader.readAsArrayBuffer(fileObjectOrBlob);
        }

        // --- 5. 波形サンプラー (セクション2) ---

        function loadWaveform(fileName) {
            const buffer = sourceAudioBuffers.get(fileName);
            if (!buffer) {
                log(`Source audio ${fileName} not found.`, true);
                return;
            }
            currentSamplerBuffer = buffer;
            currentSamplerFileName = fileName;
            sampleFileNameInput.value = `cut_${fileName.split('.')[0]}.m44`; // デフォルトファイル名
            log(`Loaded ${fileName} into sampler.`);
            
            // ズームと選択をリセット
            selectionStart = 0;
            selectionEnd = 0;
            zoomLevel = 1;
            viewOffset = 0;
            
            updateSelectionInfo();
            drawWaveform();
        }

        function drawWaveform() {
            if (!currentSamplerBuffer || !canvasCtx) return;

            const width = waveformCanvas.width;
            const height = waveformCanvas.height;
            const data = currentSamplerBuffer.getChannelData(0); // チャンネル0
            
            canvasCtx.fillStyle = '#000000'; // 黒背景
            canvasCtx.fillRect(0, 0, width, height);

            canvasCtx.lineWidth = 1;

            const totalSamples = data.length;
            const viewSamples = Math.floor(totalSamples / zoomLevel); // 現在のビューに表示されるサンプル数
            const startSample = Math.max(0, viewOffset);
            const endSample = Math.min(totalSamples, startSample + viewSamples);
            
            const samplesPerPixel = viewSamples / width;

            // 波形描画 (緑)
            canvasCtx.strokeStyle = '#34d399'; // 明るい緑
            canvasCtx.beginPath();

            for (let i = 0; i < width; i++) {
                const sampleIndex = Math.floor(startSample + (i * samplesPerPixel));
                
                // 1ピクセル内の最小値と最大値を探す (簡易版)
                let min = 1.0;
                let max = -1.0;
                const lookAhead = Math.max(1, Math.floor(samplesPerPixel));
                
                for(let j=0; j < lookAhead; j++) {
                    const idx = sampleIndex + j;
                    if(idx >= endSample) break;
                    const sample = data[idx];
                    if (sample < min) min = sample;
                    if (sample > max) max = sample;
                }

                const yMax = (1 - max) * height / 2;
                const yMin = (1 - min) * height / 2;
                
                canvasCtx.moveTo(i, yMax);
                canvasCtx.lineTo(i, yMin);
            }
            canvasCtx.stroke();

            // 選択範囲の描画 (半透明の緑)
            if (selectionEnd > selectionStart) {
                const selStartPixel = (selectionStart - startSample) / samplesPerPixel;
                const selEndPixel = (selectionEnd - startSample) / samplesPerPixel;

                if (selStartPixel < width && selEndPixel > 0) {
                    canvasCtx.fillStyle = 'rgba(74, 222, 128, 0.4)';
                    canvasCtx.fillRect(
                        Math.max(0, selStartPixel), 
                        0, 
                        Math.min(width, selEndPixel) - Math.max(0, selStartPixel), 
                        height
                    );
                }
            }
        }

        function updateSelectionInfo() {
            if (!currentSamplerBuffer) {
                selectionInfo.textContent = "Drag: Select / Wheel: Pan / Ctrl+Wheel: Zoom";
                return;
            }
            const duration = (selectionEnd - selectionStart) / currentSamplerBuffer.sampleRate * 1000;
            selectionInfo.textContent = `Sel: ${duration.toFixed(1)} ms (${selectionStart} - ${selectionEnd} samples) | Wheel: Pan / Ctrl+Wheel: Zoom`;
        }

        // サンプラーのズームとパン
        function setZoom(newZoom, anchorRatio = 0.5) {
            const totalSamples = currentSamplerBuffer ? currentSamplerBuffer.length : 1;
            const oldViewSamples = totalSamples / zoomLevel;
            const newViewSamples = totalSamples / newZoom;
            
            const anchorSample = viewOffset + oldViewSamples * anchorRatio;
            
            zoomLevel = Math.max(1, newZoom); // 最小ズームは1 (全景)
            
            // 最大ズーム (例: 1ピクセル=10サンプル)
            const maxZoom = totalSamples / (waveformCanvas.width * 10); 
            if (zoomLevel > maxZoom) zoomLevel = maxZoom;
            
            viewOffset = Math.max(0, anchorSample - (newViewSamples * anchorRatio));
            
            // viewOffsetが範囲外に行かないように調整
            if (viewOffset + newViewSamples > totalSamples) {
                viewOffset = totalSamples - newViewSamples;
            }
            if (viewOffset < 0) viewOffset = 0;

            drawWaveform();
        }

        function setPan(delta) {
            if (zoomLevel === 1) return; // 全景表示時はパンしない
            
            const totalSamples = currentSamplerBuffer.length;
            const viewSamples = totalSamples / zoomLevel;
            
            // スクロール量を調整 (ピクセル単位からサンプル単位へ)
            const panAmount = (delta * viewSamples) / 500; // 500は感度調整
            
            viewOffset += panAmount;
            
            // 範囲制限
            if (viewOffset < 0) viewOffset = 0;
            if (viewOffset + viewSamples > totalSamples) {
                viewOffset = totalSamples - viewSamples;
            }
            
            drawWaveform();
        }

        zoomInButton.addEventListener('click', () => currentSamplerBuffer && setZoom(zoomLevel * 1.5));
        zoomOutButton.addEventListener('click', () => currentSamplerBuffer && setZoom(zoomLevel / 1.5));
        zoomAllButton.addEventListener('click', () => {
            if (!currentSamplerBuffer) return;
            zoomLevel = 1;
            viewOffset = 0;
            drawWaveform();
        });

        // サンプラーのイベントリスナー
        let isDragging = false;

        function getSampleFromX(x) {
            const rect = waveformCanvas.getBoundingClientRect();
            const relativeX = x - rect.left;
            const pixelRatio = relativeX / rect.width;

            const totalSamples = currentSamplerBuffer.length;
            const viewSamples = totalSamples / zoomLevel;
            const startSample = viewOffset;
            
            return Math.floor(startSample + (pixelRatio * viewSamples));
        }

        waveformCanvas.addEventListener('mousedown', (e) => {
            if (!currentSamplerBuffer) return;
            isDragging = true;
            selectionStart = getSampleFromX(e.clientX);
            selectionEnd = selectionStart;
            drawWaveform();
            updateSelectionInfo();
        });

        waveformCanvas.addEventListener('mousemove', (e) => {
            if (!isDragging || !currentSamplerBuffer) return;
            selectionEnd = getSampleFromX(e.clientX);
            
            // 左右逆ドラッグ対応
            if (selectionEnd < selectionStart) {
                const temp = selectionStart;
                selectionStart = selectionEnd;
                selectionEnd = temp;
            }
            
            drawWaveform();
            updateSelectionInfo();
        });

        waveformCanvas.addEventListener('mouseup', () => {
            isDragging = false;
        });
        waveformCanvas.addEventListener('mouseleave', () => {
            isDragging = false;
        });

        waveformCanvas.addEventListener('wheel', (e) => {
            e.preventDefault();
            if (!currentSamplerBuffer) return;

            if (e.ctrlKey) {
                // ズーム (Ctrl + Wheel)
                const rect = waveformCanvas.getBoundingClientRect();
                const anchorRatio = (e.clientX - rect.left) / rect.width;
                const zoomFactor = e.deltaY < 0 ? 1.5 : 1 / 1.5;
                setZoom(zoomLevel * zoomFactor, anchorRatio);
            } else {
                // パン (Wheel)
                setPan(e.deltaY);
            }
        });

        // サンプルの切り出し保存
        cutButton.addEventListener('click', async () => {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲
            
            await cutAndSaveSample();
        });

        async function cutAndSaveSample() {
            if (!currentSamplerBuffer || selectionEnd <= selectionStart) {
                log('No selection made in sampler.', true);
                return;
            }

            const fileName = sampleFileNameInput.value;
            if (!fileName) {
                log('Please enter a file name for the cut sample.', true);
                return;
            }
            
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio();
            // ▲▲▲ 修正 ▲▲▲

            try {
                const sampleRate = audioContext.sampleRate;
                const numChannels = currentSamplerBuffer.numberOfChannels;
                const frameCount = selectionEnd - selectionStart;

                if (frameCount <= 0) {
                    log('Invalid selection length.', true);
                    return;
                }

                // 新しいAudioBufferを作成
                const newBuffer = audioContext.createBuffer(numChannels, frameCount, sampleRate);

                // データをコピー
                for (let i = 0; i < numChannels; i++) {
                    const channelData = currentSamplerBuffer.getChannelData(i);
                    const newChannelData = newBuffer.getChannelData(i);
                    // getChannelDataの第2引数（startInChannel）を使ってコピー
                    // copyToChannel(source, channelNumber, bufferOffset)
                    // newChannelData.set(channelData.subarray(selectionStart, selectionEnd));
                    
                    // 元のバッファからスライスして新しいバッファにセット
                    const slicedData = channelData.slice(selectionStart, selectionEnd);
                    newChannelData.set(slicedData, 0);
                }

                // AudioBufferをBlob (WAV) に変換してaddAudioFileに渡す
                const wavBlob = bufferToWave(newBuffer);
                addAudioFile(fileName, wavBlob);
                
                log(`Cut and saved ${fileName} to bank.`);

            } catch (e) {
                log(`Error cutting sample: ${e.message}`, true);
                console.error(e);
            }
        }

        // --- 6. MML再生エンジン ---

        playButton.addEventListener('click', async () => {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲

            // 簡易BATパーサー
            const batContent = editors.bat.getContent();
            const lines = batContent.split('\n');
            
            let zmsFile = null;
            let cfgFile = null;

            lines.forEach(line => {
                const parts = line.trim().split(/\s+/); // 複数の空白で分割
                if (parts[0].toLowerCase() === 'zp' && parts[1]) {
                    zmsFile = parts[1];
                }
                // 'zmusic -d' を .cfg ファイルのロードトリガーとする
                if (line.trim().toLowerCase() === 'zmusic -d') {
                    // .zms ファイル名から .cfg ファイル名を推測
                    if (zmsFile) {
                        cfgFile = zmsFile.replace(/\.zms$/i, '.cfg');
                    } else {
                        // zpコマンドより先にzmusic -dがある場合 (gabba.batの例)
                        // アクティブなZMSエディタのファイル名から推測
                        const activeZmsName = editors.zms.getFileName();
                        cfgFile = activeZmsName.replace(/\.zms$/i, '.cfg');
                    }
                }
            });

            if (zmsFile) {
                // .cfgファイルが指定されたか確認
                if (!cfgFile) {
                    log('Warning: "zmusic -d" not found in BAT. CFG file may not be loaded.', true);
                    // フォールバック: .zms と同名の .cfg を探す
                    cfgFile = zmsFile.replace(/\.zms$/i, '.cfg');
                }
                
                // 対応するエディタからMMLとCFGを取得
                let mmlContent = null;
                let cfgContent = null;
                
                if (editors.zms.getFileName() === zmsFile) {
                    mmlContent = editors.zms.getContent();
                } else {
                    log(`Error: ZMS file "${zmsFile}" not found in active editors.`, true);
                    return;
                }
                
                if (editors.cfg.getFileName() === cfgFile) {
                    cfgContent = editors.cfg.getContent();
                } else {
                    log(`Warning: CFG file "${cfgFile}" not found. Playing without samples.`, true);
                    cfgContent = ""; // 空のCFG
                }
                
                log(`Executing: zp ${zmsFile} (with ${cfgFile})`);
                await startMML(mmlContent, cfgContent);

            } else {
                log('No "zp" command found in BAT file.', true);
            }
        });

        stopButton.addEventListener('click', async () => {
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲
            
            stopMML();
            log('STOP.BAT executed. All sounds stopped.');
        });

        async function startMML(mml, cfg) {
            stopMML(); // 既存の再生を停止
            
            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲

            // 1. CFGをパースしてノートマップを作成
            const noteMap = parseCFG(cfg);
            log(`CFG parsed. ${noteMap.size} samples mapped.`);

            // 2. MMLをパースしてノートイベントのリストを作成
            // 簡易パーサー: [ {note, time, duration}, ... ]
            // TODO: もっと高機能なMMLパーサーが必要
            // ここでは簡易的なデモ再生
            
            nextNoteTime = audioContext.currentTime;
            
            // 簡易MMLパーサー (デモ)
            const lines = mml.split('\n');
            let currentOctave = 4;
            let currentLength = 4; // l4
            tempo = 120; // デフォルトテンポ
            
            // テンポ指定 (t)
            const tempoMatch = mml.match(/t(\d+)/i);
            if (tempoMatch) {
                tempo = parseFloat(tempoMatch[1]);
            }
            const secPerBeat = 60.0 / tempo;
            
            const schedule = [];

            lines.forEach(line => {
                if (line.startsWith(';')) return; // コメント
                
                let track = line.split(' ')[0]; // トラックID (A, B, C...)
                if (track.length > 2) track = 'A'; // デフォルト

                const commands = line.substring(track.length).trim();
                
                let i = 0;
                while (i < commands.length) {
                    let char = commands[i];
                    i++;
                    
                    switch (char.toLowerCase()) {
                        case 'o':
                            currentOctave = parseInt(commands[i]);
                            i++;
                            break;
                        case 'l':
                            currentLength = parseInt(commands[i]); // TODO: 複数桁
                            i++;
                            break;
                        case '<': currentOctave--; break;
                        case '>': currentOctave++; break;
                        case 'c': case 'd': case 'e': case 'f': case 'g': case 'a': case 'b':
                            // TODO: #, +, - の処理
                            // TODO: 付点(.)の処理
                            // TODO: 長さ指定 (c16, c4)
                            
                            let noteName = char.toLowerCase();
                            if (commands[i] === '+' || commands[i] === '#') {
                                noteName += '#';
                                i++;
                            }
                            if (commands[i] === '-') {
                                noteName += 'b'; // フラットは未対応
                                i++;
                            }
                            
                            const key = `o${currentOctave}${noteName}`;
                            const durationSec = secPerBeat * (4 / currentLength);
                            
                            schedule.push({ key: key, time: nextNoteTime, duration: durationSec });
                            nextNoteTime += durationSec;
                            break;
                        case 'r':
                            // TODO: 長さ指定
                            const restDurationSec = secPerBeat * (4 / currentLength);
                            nextNoteTime += restDurationSec;
                            break;
                    }
                }
            });
            
            log(`MML parsed. Scheduling ${schedule.length} notes.`);

            // 3. ノートイベントをスケジュール
            schedule.forEach(note => {
                const sampleName = noteMap.get(note.key);
                if (sampleName) {
                    playSample(sampleName, note.time);
                } else {
                    //log(`Note ${note.key} not mapped in CFG.`, true);
                }
            });
        }
        
        function stopMML() {
            // TODO: MMLの再生を停止
            // スケジュールされた音源を停止
            activeSources.forEach(source => {
                try {
                    source.stop(0);
                } catch(e) {
                    // すでに停止している場合のエラーを無視
                }
            });
            activeSources = [];
            nextNoteTime = 0.0;
            log('MML playback stopped.');
        }

        // CFGパーサー (簡易版)
        function parseCFG(cfgContent) {
            const map = new Map();
            // .o2c = kick.m44 または .o2f+= hho.m44
            // ▼▼▼ 修正: 拡張子を許可 ▼▼▼
            const regex = /\.o([0-9])([a-g])([#\+]?)?\s*(\+)?=\s*([^\s]+(\.(m44|wav|mp3|m4a|flac))?)/i;
            // ▲▲▲ 修正 ▲▲▲
            
            cfgContent.split('\n').forEach(line => {
                const match = line.match(regex);
                if (match) {
                    const octave = match[1];
                    let note = match[2];
                    const sharp = match[3];
                    //const multi = match[4]; // += は未対応
                    const fileName = match[5];
                    
                    if (sharp === '+' || sharp === '#') {
                        note += '#';
                    }
                    
                    const key = `o${octave}${note}`;
                    map.set(key, fileName);
                }
            });
            return map;
        }

        // サンプル再生
        async function playSample(fileName, when = 0) {
            const buffer = audioBuffers.get(fileName);
            if (!buffer) {
                log(`Sample not found in bank: ${fileName}`, true);
                return;
            }

            // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
            await initAudio(); 
            // ▲▲▲ 修正 ▲▲▲
            
            try {
                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(masterGain);
                source.start(when);
                
                // 再生が終わったらリストから削除
                source.onended = () => {
                    activeSources = activeSources.filter(s => s !== source);
                };
                activeSources.push(source);

            } catch(e) {
                log(`Error playing sample ${fileName}: ${e.message}`, true);
            }
        }

        // --- 7. プロジェクトの保存/読み込み ---
        
        saveProjectButton.addEventListener('click', async () => {
            log('Saving project... (This may take a moment)');
            try {
                const projectData = {
                    version: 1,
                    directory: document.getElementById('currentDir').value,
                    editors: {
                        bat: { name: editors.bat.getFileName(), content: editors.bat.getContent() },
                        stop: { name: editors.stop.getFileName(), content: editors.stop.getContent() },
                        cfg: { name: editors.cfg.getFileName(), content: editors.cfg.getContent() },
                        zms: { name: editors.zms.getFileName(), content: editors.zms.getContent() },
                    },
                    sampleBank: [],
                    sourceAudio: [],
                };

                // 1. サンプルバンク (audioBuffers)
                for (const [name, buffer] of audioBuffers.entries()) {
                    const wavBlob = bufferToWave(buffer);
                    const base64 = await blobToBase64(wavBlob);
                    projectData.sampleBank.push({ name, data: base64 });
                }

                // 2. ソース音声 (sourceAudioBuffers)
                for (const [name, buffer] of sourceAudioBuffers.entries()) {
                    const wavBlob = bufferToWave(buffer);
                    const base64 = await blobToBase64(wavBlob);
                    projectData.sourceAudio.push({ name, data: base64 });
                }

                // JSONファイルとしてダウンロード
                const jsonString = JSON.stringify(projectData);
                const blob = new Blob([jsonString], { type: 'application/json' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'web_zmusic_project.json';
                a.click();
                URL.revokeObjectURL(url);
                log('Project saved successfully.');

            } catch (e) {
                log(`Error saving project: ${e.message}`, true);
                console.error(e);
            }
        });

        loadProjectInput.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (!file) return;
            
            loadProject(file);
            
            // 同じファイルを選択し直せるように
            loadProjectInput.value = '';
        });

        async function loadProject(file) {
            log('Loading project...');
            const reader = new FileReader();
            
            reader.onload = async (e) => {
                // ▼▼▼ 修正: AudioContextを起動 ▼▼▼
                await initAudio();
                // ▲▲▲ 修正 ▲▲▲
                
                try {
                    const projectData = JSON.parse(e.target.result);
                    
                    // 0. 状態をリセット
                    stopMML();
                    audioBuffers.clear();
                    sourceAudioBuffers.clear();
                    fileList.innerHTML = '<p class="text-gray-500">...</p>';
                    sourceAudioList.innerHTML = '<p class="text-gray-500">...</p>';
                    currentSamplerBuffer = null;
                    drawWaveform();

                    // 1. ディレクトリとエディタ
                    document.getElementById('currentDir').value = projectData.directory || 'A:\\';
                    
                    editors.bat.setFileName(projectData.editors.bat.name);
                    editors.bat.setContent(projectData.editors.bat.content);
                    editors.stop.setFileName(projectData.editors.stop.name);
                    editors.stop.setContent(projectData.editors.stop.content);
                    editors.cfg.setFileName(projectData.editors.cfg.name);
                    editors.cfg.setContent(projectData.editors.cfg.content);
                    editors.zms.setFileName(projectData.editors.zms.name);
                    editors.zms.setContent(projectData.editors.zms.content);
                    // TODO: スマホ用タブのDOMも更新する必要がある (現状はインスタンス参照なので大丈夫かも？要確認)
                    // -> クローンなので、別途更新が必要
                    updateClonedEditors();


                    // 2. サンプルバンク
                    if (projectData.sampleBank && projectData.sampleBank.length > 0) {
                        log(`Loading ${projectData.sampleBank.length} samples from bank...`);
                        for (const sample of projectData.sampleBank) {
                            try {
                                const blob = base64toBlob(sample.data, 'audio/wav');
                                await addAudioFile(sample.name, blob); // 既存の関数を再利用
                            } catch (loadErr) {
                                log(`Failed to load sample ${sample.name}: ${loadErr.message}`, true);
                            }
                        }
                    }

                    // 3. ソース音声
                    if (projectData.sourceAudio && projectData.sourceAudio.length > 0) {
                        log(`Loading ${projectData.sourceAudio.length} source audio files...`);
                        for (const source of projectData.sourceAudio) {
                            try {
                                const blob = base64toBlob(source.data, 'audio/wav');
                                await addSourceAudioFile(source.name, blob); // 既存の関数を再利用
                            } catch (loadErr) {
                                log(`Failed to load source audio ${source.name}: ${loadErr.message}`, true);
                            }
                        }
                    }

                    log('Project loaded successfully.');

                } catch (err) {
                    log(`Error loading project: ${err.message}`, true);
                    console.error(err);
                }
            };
            
            reader.readAsText(file);
        }
        
        // スマホ用クローンエディタのDOM内容をマスターと同期させる
        function updateClonedEditors() {
            // BAT
            const batCloneContainer = document.getElementById('tab-bat');
            batCloneContainer.innerHTML = ''; // 古いDOMを削除
            batCloneContainer.appendChild(editors.bat.container.cloneNode(true));
            // STOP
            const stopCloneContainer = document.getElementById('tab-stop');
            stopCloneContainer.innerHTML = '';
            stopCloneContainer.appendChild(editors.stop.container.cloneNode(true));
            // CFG
            const cfgCloneContainer = document.getElementById('tab-cfg');
            cfgCloneContainer.innerHTML = '';
            cfgCloneContainer.appendChild(editors.cfg.container.cloneNode(true));
            // ZMS
            const zmsCloneContainer = document.getElementById('tab-zms');
            zmsCloneContainer.innerHTML = '';
            zmsCloneContainer.appendChild(editors.zms.container.cloneNode(true));
        }

        // --- 8. ユーティリティ関数 ---

        // Base64 <-> Blob
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => resolve(reader.result.split(',')[1]); // "data:..." の部分を除去
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }
        
        function base64toBlob(base64, contentType = '') {
            const byteCharacters = atob(base64);
            const byteArrays = [];
            for (let offset = 0; offset < byteCharacters.length; offset += 512) {
                const slice = byteCharacters.slice(offset, offset + 512);
                const byteNumbers = new Array(slice.length);
                for (let i = 0; i < slice.length; i++) {
                    byteNumbers[i] = slice.charCodeAt(i);
                }
                const byteArray = new Uint8Array(byteNumbers);
                byteArrays.push(byteArray);
            }
            return new Blob(byteArrays, {type: contentType});
        }


        // AudioBufferをWAV (Blob) に変換する (github.com/mattdiamond/RecordRTC)
        function bufferToWave(buffer) {
            let numOfChan = buffer.numberOfChannels,
                len = buffer.length * numOfChan * 2 + 44,
                ab = new ArrayBuffer(len),
                view = new DataView(ab),
                chans = [],
                i,
                sample,
                offset = 0,
                pos = 0;

            // ヘッダー
            setUint32(0x46464952); // "RIFF"
            setUint32(len - 8); // file length - 8
            setUint32(0x45564157); // "WAVE"
            setUint32(0x20746d66); // "fmt " chunk
            setUint32(16); // length = 16
            setUint16(1); // PCM (リニア量子化)
            setUint16(numOfChan);
            setUint32(buffer.sampleRate);
            setUint32(buffer.sampleRate * 2 * numOfChan); // byte rate
            setUint16(numOfChan * 2); // block align
            setUint16(16); // bits per sample
            setUint32(0x61746164); // "data" - chunk
            setUint32(len - 44); // data length

            // チャンネルデータを取得
            for (i = 0; i < numOfChan; i++)
                chans.push(buffer.getChannelData(i));

            // データを書き込む
            offset = 44;
            for (i = 0; i < buffer.length; i++) {
                for (let ch = 0; ch < numOfChan; ch++) {
                    sample = Math.max(-1, Math.min(1, chans[ch][i]));
                    sample = (0.5 + sample * 32767.5) | 0; // 16bit PCM
                    view.setInt16(offset, sample, true); // リトルエンディアン
                    offset += 2;
                }
            }
            
            return new Blob([view], { type: 'audio/wav' });

            function setUint16(data) {
                view.setUint16(pos, data, true);
                pos += 2;
            }
            function setUint32(data) {
                view.setUint32(pos, data, true);
                pos += 4;
            }
        }

        // --- 初期化処理 ---
        log('Page loaded. Click Play/Record or Load files to start AudioContext.');
        // ページロード時ではなく、最初のユーザー操作でinitAudio()が呼ばれるのを待つ
        
        // ウィンドウリサイズ時にキャンバスを再描画
        window.addEventListener('resize', () => {
            waveformCanvas.width = waveformCanvas.clientWidth;
            waveformCanvas.height = waveformCanvas.clientHeight;
            drawWaveform();
        });
        
        // 初期描画
        (new ResizeObserver(() => {
            waveformCanvas.width = waveformCanvas.clientWidth;
            waveformCanvas.height = waveformCanvas.clientHeight;
            drawWaveform();
        })).observe(waveformCanvas);


    </script>

</body>
</html>
